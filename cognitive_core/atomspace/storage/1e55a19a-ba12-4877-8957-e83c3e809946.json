{
  "uuid": "1e55a19a-ba12-4877-8957-e83c3e809946",
  "atom_type": "PolicySection",
  "name": "Page 1",
  "content": {
    "title": "Page 1",
    "text": "Scaling Laws for Neural Language Models\nJared Kaplan\u0003\nJohns Hopkins University, OpenAI\njaredk@jhu.eduSam McCandlish\u0003\nOpenAI\nsam@openai.com\nTom Henighan\nOpenAI\nhenighan@openai.comTom B. Brown\nOpenAI\ntom@openai.comBenjamin Chess\nOpenAI\nbchess@openai.comRewon Child\nOpenAI\nrewon@openai.com\nScott Gray\nOpenAI\nscott@openai.comAlec Radford\nOpenAI\nalec@openai.comJeffrey Wu\nOpenAI\njeffwu@openai.comDario Amodei\nOpenAI\ndamodei@openai.com\nAbstract\nWe study empirical scaling laws for language model performance on the cross-entropy loss.\nThe loss scales as a power-law with model size, dataset size, and the amount of compute\nused for training, with some trends spanning more than seven orders of magnitude. Other\narchitectural details such as network width or depth have minimal effects within a wide\nrange. Simple equations govern the dependence of overﬁtting on model/dataset size and the\ndependence of training speed on model size. These relationships allow us to determine the\noptimal allocation of a ﬁxed compute budget. Larger models are signiﬁcantly more sample-\nefﬁcient, such that optimally compute-efﬁcient training involves training very large models\non a relatively modest amount of data and stopping signiﬁcantly before convergence.\n\u0003Equal contribution.\nContributions: Jared Kaplan and Sam McCandlish led the research. Tom Henighan contributed the LSTM ex-\nperiments. Tom Brown, Rewon Child, and Scott Gray, and Alec Radford developed the optimized Transformer\nimplementation. Jeff Wu, Benjamin Chess, and Alec Radford developed the text datasets. Dario Amodei provided\nguidance throughout the project.arXiv:2001.08361v1  [cs.LG]  23 Jan 2020",
    "page": 1
  },
  "metadata": {
    "source": "docs/2001.08361.pdf"
  },
  "attention_value": {
    "short_term": 0.2,
    "long_term": 0.4335948456850463,
    "very_long_term": 0.0
  },
  "truth_value": {
    "strength": 1.0,
    "confidence": 1.0
  },
  "incoming_links": [],
  "outgoing_links": [],
  "created_at": "2025-10-21T01:56:34.767991",
  "updated_at": "2025-10-21T02:01:00.968809",
  "last_accessed": "2025-10-21T01:56:34.791407"
}